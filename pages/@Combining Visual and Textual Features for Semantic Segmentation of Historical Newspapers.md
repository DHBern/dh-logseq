tags:: [[Computer Science - Computation and Language]], [[Computer Science - Computer Vision and Pattern Recognition]], [[Computer Science - Information Retrieval]], [[Computer Science - Machine Learning]]
date:: [[Dec 14th, 2020]]
extra:: arXiv: 2002.06144
title:: @Combining Visual and Textual Features for Semantic Segmentation of Historical Newspapers
item-type:: [[journalArticle]]
access-date:: 2021-06-08T11:16:15Z
original-title:: Combining Visual and Textual Features for Semantic Segmentation of Historical Newspapers
url:: http://arxiv.org/abs/2002.06144
publication-title:: arXiv:2002.06144 [cs]
authors:: [[Raphaël Barman]], [[Maud Ehrmann]], [[Simon Clematide]], [[Sofia Ares Oliveira]], [[Frédéric Kaplan]]
library-catalog:: arXiv.org
links:: [Local library](zotero://select/groups/2386895/items/YW2VGBI6), [Web library](https://www.zotero.org/groups/2386895/items/YW2VGBI6)

- [[Abstract]]
	- The massive amounts of digitized historical documents acquired over the last decades naturally lend themselves to automatic processing and exploration. Research work seeking to automatically process facsimiles and extract information thereby are multiplying with, as a first essential step, document layout analysis. If the identification and categorization of segments of interest in document images have seen significant progress over the last years thanks to deep learning techniques, many challenges remain with, among others, the use of finer-grained segmentation typologies and the consideration of complex, heterogeneous documents such as historical newspapers. Besides, most approaches consider visual features only, ignoring textual signal. In this context, we introduce a multimodal approach for the semantic segmentation of historical newspapers that combines visual and textual features. Based on a series of experiments on diachronic Swiss and Luxembourgish newspapers, we investigate, among others, the predictive power of visual and textual features and their capacity to generalize across time and sources. Results show consistent improvement of multimodal models in comparison to a strong visual baseline, as well as better robustness to high material variance.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/2002.06144) {{zotero-imported-file P6JAGSW4, "2002.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/2002.06144.pdf) {{zotero-imported-file NAYWLQG9, "Barman et al. - 2020 - Combining Visual and Textual Features for Semantic.pdf"}}