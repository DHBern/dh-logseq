links:: [Local library](zotero://select/groups/2386895/items/7Z59IWMF), [Web library](https://www.zotero.org/groups/2386895/items/7Z59IWMF)
authors:: [[Rebecca Marvin]], [[Tal Linzen]]
tags:: [[Computer Science - Computation and Language]]
date:: [[Aug 27th, 2018]]
item-type:: [[preprint]]
title:: @Targeted Syntactic Evaluation of Language Models

- [[Abstract]]
	- We present a dataset for evaluating the grammaticality of the predictions of a language model. We automatically construct a large number of minimally different pairs of English sentences, each consisting of a grammatical and an ungrammatical sentence. The sentence pairs represent different variations of structure-sensitive phenomena: subject-verb agreement, reflexive anaphora and negative polarity items. We expect a language model to assign a higher probability to the grammatical sentence than the ungrammatical one. In an experiment using this data set, an LSTM language model performed poorly on many of the constructions. Multi-task training with a syntactic objective (CCG supertagging) improved the LSTM's accuracy, but a large gap remained between its performance and the accuracy of human participants recruited online. This suggests that there is considerable room for improvement over LSTMs in capturing syntax in a language model.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/1808.09031) {{zotero-imported-file 3A3TK25G, "1808.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/1808.09031.pdf) {{zotero-imported-file U4C85HKP, "Marvin und Linzen - 2018 - Targeted Syntactic Evaluation of Language Models.pdf"}}
- [[Notes]]
	- Comment: Accepted to EMNLP 2018