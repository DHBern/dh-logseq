tags:: [[*****]], [[act_ContentAnalysis]], [[goal_Analysis]], [[meta_GiveOverview]], [[t_TopicModeling]]
date:: 2012
issue:: 4
doi:: 10.1145/2133806.2133826
title:: @Introduction to Probabilistic Topic Models
pages:: 77–84
volume:: 55
item-type:: [[journalArticle]]
original-title:: Introduction to Probabilistic Topic Models
language:: en
publication-title:: Communications of the ACM
authors:: [[David M. Blei]]
links:: [Local library](zotero://select/groups/2386895/items/6925L632), [Web library](https://www.zotero.org/groups/2386895/items/6925L632)

- [[Abstract]]
	- Abstract: Probabilistic topic models are a suite of algorithms whose aim is to discover the hidden thematic structure in large archives of documents. In this article, we review the main ideas of this ⬚eld, survey the current state-of-the-art, and describe some promising future directions. We ⬚rst describe latent Dirichlet allocation (LDA) [8], which is the simplest kind of topic model. We discuss its connections to probabilistic modeling,
	  and describe two kinds of algorithms for topic discovery. We then survey the growing
	  body of research that extends and applies topic models in interesting ways. These
	  extensions have been developed by relaxing some of the statistical assumptions of LDA,
	  incorporating meta-data into the analysis of the documents, and using similar kinds
	  of models on a diversity of data types such as social networks, images and genetics.
	  Finally, we give our thoughts as to some of the important unexplored directions for
	  topic modeling. These include rigorous methods for checking models built for data
	  exploration, new approaches to visualizing text and other high dimensional data, and
	  moving beyond traditional information engineering applications towards using topic models for more scienti⬚c ends.