date:: 2022
doi:: https://doi.org/10.1162/DAED_a_01905
title:: @Human Language Understanding & Reasoning
pages:: 127-138
item-type:: [[journalArticle]]
access-date:: 2022-05-03T07:50:41Z
original-title:: Human Language Understanding & Reasoning
language:: en
url:: https://www.amacad.org/publication/human-language-understanding-reasoning
publication-title:: "DÃ¦dalus, the Journal of the American Academy of Arts & Sciences"
authors:: [[Christopher D. Manning]]
links:: [Local library](zotero://select/groups/2386895/items/LDDW3LYA), [Web library](https://www.zotero.org/groups/2386895/items/LDDW3LYA)

- [[Abstract]]
	- The last decade has yielded dramatic and quite surprising breakthroughs in natural language processing through the use of simple artificial neural network computations, replicated on a very large scale and trained over exceedingly large amounts of data. The resulting pretrained language models, such as BERT and GPT-3, have provided a powerful universal language understanding and generation base, which can easily be adapted to many understanding, writing, and reasoning tasks. These models show the first inklings of a more general form of artificial intelligence, which may lead to powerful foundation models in domains of sensory experience beyond just language.
- [[Attachments]]
	- [Snapshot](https://www.amacad.org/publication/human-language-understanding-reasoning) {{zotero-imported-file QKV4U363, "human-language-understanding-reasoning.html"}}