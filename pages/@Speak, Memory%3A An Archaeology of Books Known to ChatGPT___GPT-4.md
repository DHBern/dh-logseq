links:: [Local library](zotero://select/groups/2386895/items/VXVPKGNL), [Web library](https://www.zotero.org/groups/2386895/items/VXVPKGNL)
authors:: [[Kent K. Chang]], [[Mackenzie Cramer]], [[Sandeep Soni]], [[David Bamman]]
tags:: [[Computer Science - Computation and Language]]
date:: [[Apr 28th, 2023]]
item-type:: [[preprint]]
title:: @Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4

- [[Abstract]]
	- In this work, we carry out a data archaeology to infer books that are known to ChatGPT and GPT-4 using a name cloze membership inference query. We find that OpenAI models have memorized a wide collection of copyrighted materials, and that the degree of memorization is tied to the frequency with which passages of those books appear on the web. The ability of these models to memorize an unknown set of books complicates assessments of measurement validity for cultural analytics by contaminating test data; we show that models perform much better on memorized books than on non-memorized books for downstream tasks. We argue that this supports a case for open models whose training data is known.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/2305.00118) {{zotero-imported-file NGEVQVRQ, "2305.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/2305.00118.pdf) {{zotero-imported-file PFE3VT8U, "Chang et al. - 2023 - Speak, Memory An Archaeology of Books Known to Ch.pdf"}}